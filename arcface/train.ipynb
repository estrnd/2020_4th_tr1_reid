{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "conditional-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "METRIC_DIM = 512\n",
    "IMG_SIZE = 112\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beautiful-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 이미지 리스트\n",
    "BASE_DIR = '/data/kts123/aihub/reid'\n",
    "train_imgs = '/data/kts123/aihub/reid/img_list_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_imgs)\n",
    "for kls, df_i in tqdm(df.groupby('KLS_IDX')):\n",
    "    dst_dir = f'train_imgs/{kls:05d}'\n",
    "    Path(dst_dir).mkdir(exist_ok=True, parents=True)\n",
    "    for name in df_i['NAME'].values:\n",
    "        src = f'{BASE_DIR}/{name}'\n",
    "        dst = f'{dst_dir}/{Path(name).name}'\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ordered-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val 이미지 리스트\n",
    "val_imgs = '/data/kts123/aihub/reid/img_list_val.txt'\n",
    "df = pd.read_csv(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-offset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kls, df_i in tqdm(df.groupby('KLS_IDX')):\n",
    "    dst_dir = f'val_imgs/{kls:05d}'\n",
    "    Path(dst_dir).mkdir(exist_ok=True, parents=True)\n",
    "    for name in df_i['NAME'].values:\n",
    "        src = f'{BASE_DIR}/{name}'\n",
    "        dst = f'{dst_dir}/{Path(name).name}'\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "removed-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FolderDataset(Dataset):\n",
    "    def __init__(self, root_dir, phase = 'train', trsf = lambda e: e):\n",
    "        imgs_total = glob(f'{root_dir}/*/*.jpg')\n",
    "        imgs_train = [e for e in imgs_total if int(Path(e).stem) < 100]\n",
    "        imgs_val   = [e for e in imgs_total if int(Path(e).stem) >= 100]\n",
    "        self.imgs = imgs_train if phase == 'train' else imgs_val\n",
    "        \n",
    "        self.class_names = set([p.split('/')[-2] for p in self.imgs])\n",
    "        self.class_names = sorted(list(self.class_names))\n",
    "        self.labels = [self.class_names.index(e.split('/')[-2]) for e in self.imgs]\n",
    "        self.trsf = trsf\n",
    "        \n",
    "    def num_labels(self):\n",
    "        return len(self.class_names)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.imgs[idx]\n",
    "        label = self.labels[idx]\n",
    "        im = Image.open(path)\n",
    "        im = self.trsf(im)\n",
    "        return im, label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(int(IMG_SIZE*1.2)),\n",
    "        transforms.RandomResizedCrop(size=IMG_SIZE, scale=(0.64, 1.0), ratio=(0.9, 1.1)),\n",
    "        transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.05, 0.1), value=0.5),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.05, 0.1), value=0.5),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.05, 0.1), value=0.5),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(int(IMG_SIZE*1.2)),\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets =  {phase:FolderDataset(CROP_IMG_DIR, phase, data_transforms[phase]) \n",
    "             for phase in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {phase: DataLoader(datasets[phase], batch_size=64, \n",
    "                             shuffle=True, num_workers=2, drop_last=True)\n",
    "               for phase in ['train', 'val']}\n",
    "\n",
    "len(dataloaders['train']), len(dataloaders['val']), datasets['train'].num_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, num_cls):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.num_cls = num_cls\n",
    "        self.s       = 30 \n",
    "        self.m       = 0.50 \n",
    "\n",
    "        self.weight = Parameter(torch.FloatTensor(num_cls, METRIC_DIM))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.cos_m = math.cos(self.m)\n",
    "        self.sin_m = math.sin(self.m)\n",
    "        self.th = math.cos(math.pi - self.m)\n",
    "        self.mm = math.sin(math.pi - self.m) * self.m\n",
    "        \n",
    "    def forward(self, input_features, labels):\n",
    "        cosine = F.linear(F.normalize(input_features), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "\n",
    "        #cos(a + self.m) = cos(a)*cos(self.m) - sin(a)*sin(self.m)\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        # convert label to one-hot\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, labels.view(-1, 1).long(), 1)\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TrainModel, self).__init__()\n",
    "        backbone = models.resnext50_32x4d(pretrained=True)\n",
    "        backbone.fc = nn.Linear(in_features=backbone.fc.in_features, out_features=METRIC_DIM)\n",
    "        self.backbone = backbone\n",
    "        self.metric = ArcMarginProduct(num_classes)\n",
    "        \n",
    "    def forward(self, input_imgs, labels):\n",
    "        x = self.backbone(input_imgs)\n",
    "        x = self.metric(x, labels)\n",
    "        return x\n",
    "    \n",
    "model = TrainModel(datasets['train'].num_labels())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc, best_epoch = 0.0, 0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc='epochs'):\n",
    "\n",
    "        ds_size = 0\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train(phase == 'train') # Set model to training/evaluate mode\n",
    "\n",
    "            running_loss, running_corrects = 0.0, 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase], desc=f'{phase} ep({epoch:03d})'):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                ds_size += labels.size(0)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward: track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / ds_size\n",
    "            epoch_acc = running_corrects.double() / ds_size\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc, best_epoch = epoch_acc, epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc, best_epoch\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gc21_3_3]",
   "language": "python",
   "name": "conda-env-gc21_3_3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
